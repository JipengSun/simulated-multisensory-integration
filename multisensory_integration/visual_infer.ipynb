{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset,DataLoader,sampler\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Goal of the module\n",
    "Training the visual inference model. Use the visual data to predict the position of the hand.\n",
    "\n",
    "### Input\n",
    "image\n",
    "\n",
    "### Output\n",
    "spatial_coding of the hand position\n",
    "\n",
    "### Model structure\n",
    "input-->Conv-->MaxPooling-->Conv-->MaxPooling-->FC-->FC-->Softmax\n",
    "### To do\n",
    "1. Build the visual dataset</br>\n",
    "a. Convert the videos to the images </br>\n",
    "b. Learn to build the Pytorch image dataset.\n",
    "2. Train the visual inference network to make it predict the hand position.\n",
    "3. Build a multisensory dataset</br>\n",
    "a. Align the visual and prioproceptive data.</br>\n",
    "b. Merge them in a single dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'elbow_angle', 'elbow_x', 'elbow_y', 'frame_idx', 'hand_x', 'hand_y', 'shoulder_angle', 'target_x', 'video_idx']\n",
      "       Unnamed: 0  elbow_angle  elbow_x  elbow_y  frame_idx  hand_x  hand_y  \\\n",
      "0               0       113.81     0.44     2.97          0   -1.25    2.97   \n",
      "1               1       113.81     0.29     2.99          1   -1.46    2.99   \n",
      "2               2       113.81     0.44     2.97          2   -1.25    2.97   \n",
      "3               3       116.81     0.44     2.97          3   -1.19    2.97   \n",
      "4               4       113.81     0.44     2.97          4   -1.25    2.97   \n",
      "5               5       113.81     0.60     2.94          5   -1.03    2.94   \n",
      "6               6       113.81     0.44     2.97          6   -1.25    2.97   \n",
      "7               7       110.81     0.44     2.97          7   -1.30    2.97   \n",
      "8               8       107.81     0.44     2.97          8   -1.35    2.97   \n",
      "9               9       104.81     0.44     2.97          9   -1.39    2.97   \n",
      "10             10       104.81     0.29     2.99         10   -1.59    2.99   \n",
      "11             11       101.81     0.29     2.99         11   -1.62    2.99   \n",
      "12             12       104.81     0.29     2.99         12   -1.59    2.99   \n",
      "13             13       101.81     0.29     2.99         13   -1.62    2.99   \n",
      "14             14        98.81     0.29     2.99         14   -1.65    2.99   \n",
      "15             15       101.81     0.29     2.99         15   -1.62    2.99   \n",
      "16             16       101.81     0.44     2.97         16   -1.43    2.97   \n",
      "17             17       101.81     0.29     2.99         17   -1.62    2.99   \n",
      "18             18        98.81     0.29     2.99         18   -1.65    2.99   \n",
      "19             19       101.81     0.29     2.99         19   -1.62    2.99   \n",
      "20             20       101.81     0.13     3.00         20   -1.81    3.00   \n",
      "21             21       101.81    -0.03     3.00         21   -1.99    3.00   \n",
      "22             22       101.81     0.13     3.00         22   -1.81    3.00   \n",
      "23             23       101.81    -0.03     3.00         23   -1.99    3.00   \n",
      "24             24       101.81    -0.18     2.99         24   -2.16    2.99   \n",
      "25             25        98.81    -0.18     2.99         25   -2.17    2.99   \n",
      "26             26        98.81    -0.34     2.98         26   -2.34    2.98   \n",
      "27             27        55.62    -1.03     2.82          0   -2.19    2.82   \n",
      "28             28        58.62    -1.03     2.82          1   -2.27    2.82   \n",
      "29             29        58.62    -1.17     2.76          2   -2.34    2.76   \n",
      "...           ...          ...      ...      ...        ...     ...     ...   \n",
      "10688       10688        87.01    -1.88     2.33        129   -3.37    2.33   \n",
      "10689       10689        87.01    -2.00     2.23        130   -3.42    2.23   \n",
      "10690       10690        87.01    -2.12     2.12        131   -3.46    2.12   \n",
      "10691       10691        84.01    -2.12     2.12        132   -3.38    2.12   \n",
      "10692       10692        87.01    -2.12     2.12        133   -3.46    2.12   \n",
      "10693       10693        87.01    -2.00     2.23        134   -3.42    2.23   \n",
      "10694       10694        87.01    -2.12     2.12        135   -3.46    2.12   \n",
      "10695       10695        90.01    -2.12     2.12        136   -3.53    2.12   \n",
      "10696       10696        87.01    -2.12     2.12        137   -3.46    2.12   \n",
      "10697       10697        87.01    -2.00     2.23        138   -3.42    2.23   \n",
      "10698       10698        90.01    -2.00     2.23        139   -3.49    2.23   \n",
      "10699       10699        93.01    -2.00     2.23        140   -3.56    2.23   \n",
      "10700       10700        93.01    -1.88     2.33        141   -3.50    2.33   \n",
      "10701       10701        93.01    -1.76     2.43        142   -3.44    2.43   \n",
      "10702       10702        93.01    -1.63     2.52        143   -3.36    2.52   \n",
      "10703       10703        93.01    -1.50     2.60        144   -3.28    2.60   \n",
      "10704       10704        90.01    -1.50     2.60        145   -3.23    2.60   \n",
      "10705       10705        93.01    -1.50     2.60        146   -3.28    2.60   \n",
      "10706       10706        90.01    -1.50     2.60        147   -3.23    2.60   \n",
      "10707       10707        90.01    -1.36     2.68        148   -3.14    2.68   \n",
      "10708       10708        90.01    -1.22     2.74        149   -3.04    2.74   \n",
      "10709       10709        87.01    -1.22     2.74        150   -3.00    2.74   \n",
      "10710       10710        87.01    -1.07     2.80        151   -2.90    2.80   \n",
      "10711       10711        87.01    -0.92     2.85        152   -2.79    2.85   \n",
      "10712       10712        87.01    -0.77     2.90        153   -2.67    2.90   \n",
      "10713       10713        87.01    -0.62     2.94        154   -2.55    2.94   \n",
      "10714       10714        87.01    -0.46     2.96        155   -2.42    2.96   \n",
      "10715       10715        87.01    -0.31     2.98        156   -2.28    2.98   \n",
      "10716       10716        87.01    -0.15     3.00        157   -2.14    3.00   \n",
      "10717       10717        87.01     0.01     3.00        158   -1.99    3.00   \n",
      "\n",
      "       shoulder_angle  target_x  video_idx  label  label1  \n",
      "0               81.50     -2.69          0      3      -1  \n",
      "1               84.50     -2.69          0      3      -1  \n",
      "2               81.50     -2.69          0      3      -1  \n",
      "3               81.50     -2.69          0      3      -1  \n",
      "4               81.50     -2.69          0      3      -1  \n",
      "5               78.50     -2.69          0      3      -1  \n",
      "6               81.50     -2.69          0      3      -1  \n",
      "7               81.50     -2.69          0      3      -1  \n",
      "8               81.50     -2.69          0      3      -1  \n",
      "9               81.50     -2.69          0      3      -1  \n",
      "10              84.50     -2.69          0      2      -2  \n",
      "11              84.50     -2.69          0      2      -2  \n",
      "12              84.50     -2.69          0      2      -2  \n",
      "13              84.50     -2.69          0      2      -2  \n",
      "14              84.50     -2.69          0      2      -2  \n",
      "15              84.50     -2.69          0      2      -2  \n",
      "16              81.50     -2.69          0      3      -1  \n",
      "17              84.50     -2.69          0      2      -2  \n",
      "18              84.50     -2.69          0      2      -2  \n",
      "19              84.50     -2.69          0      2      -2  \n",
      "20              87.50     -2.69          0      2      -2  \n",
      "21              90.50     -2.69          0      2      -2  \n",
      "22              87.50     -2.69          0      2      -2  \n",
      "23              90.50     -2.69          0      2      -2  \n",
      "24              93.50     -2.69          0      2      -2  \n",
      "25              93.50     -2.69          0      2      -2  \n",
      "26              96.50     -2.69          0      2      -2  \n",
      "27             109.99      0.19          1      2      -2  \n",
      "28             109.99      0.19          1      2      -2  \n",
      "29             112.99      0.19          1      2      -2  \n",
      "...               ...       ...        ...    ...     ...  \n",
      "10688          128.90     -1.56         49      1      -3  \n",
      "10689          131.90     -1.56         49      1      -3  \n",
      "10690          134.90     -1.56         49      1      -3  \n",
      "10691          134.90     -1.56         49      1      -3  \n",
      "10692          134.90     -1.56         49      1      -3  \n",
      "10693          131.90     -1.56         49      1      -3  \n",
      "10694          134.90     -1.56         49      1      -3  \n",
      "10695          134.90     -1.56         49      0      -4  \n",
      "10696          134.90     -1.56         49      1      -3  \n",
      "10697          131.90     -1.56         49      1      -3  \n",
      "10698          131.90     -1.56         49      1      -3  \n",
      "10699          131.90     -1.56         49      0      -4  \n",
      "10700          128.90     -1.56         49      0      -4  \n",
      "10701          125.90     -1.56         49      1      -3  \n",
      "10702          122.90     -1.56         49      1      -3  \n",
      "10703          119.90     -1.56         49      1      -3  \n",
      "10704          119.90     -1.56         49      1      -3  \n",
      "10705          119.90     -1.56         49      1      -3  \n",
      "10706          119.90     -1.56         49      1      -3  \n",
      "10707          116.90     -1.56         49      1      -3  \n",
      "10708          113.90     -1.56         49      1      -3  \n",
      "10709          113.90     -1.56         49      1      -3  \n",
      "10710          110.90     -1.56         49      1      -3  \n",
      "10711          107.90     -1.56         49      1      -3  \n",
      "10712          104.90     -1.56         49      1      -3  \n",
      "10713          101.90     -1.56         49      1      -3  \n",
      "10714           98.90     -1.56         49      2      -2  \n",
      "10715           95.90     -1.56         49      2      -2  \n",
      "10716           92.90     -1.56         49      2      -2  \n",
      "10717           89.90     -1.56         49      2      -2  \n",
      "\n",
      "[10718 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "src_path = '/Users/Jipeng/PycharmProjects/simulated_multisensory_integration/data/'\n",
    "file_name = 'simulated_data.csv'\n",
    "df = pd.read_csv(src_path+file_name)\n",
    "\n",
    "loc_map = range(-4,5)\n",
    "def label_function(x):\n",
    "    loc_map = range(-4,5)\n",
    "    return loc_map.index(x)\n",
    "\n",
    "feature_names = df.columns.tolist()\n",
    "print feature_names\n",
    "\n",
    "label = np.around(df['hand_x'])\n",
    "df['label'] = np.around(df['hand_x'])\n",
    "df['label1'] = df['label'].astype(np.int)\n",
    "df['label'] = df['label1'].apply(label_function)\n",
    "print (df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,dataframe,image_root,transform=None):\n",
    "        self.dataset = dataframe\n",
    "        self.image_root = image_root\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        video_idx = self.dataset.loc[idx,'video_idx']\n",
    "        frame_idx = self.dataset.loc[idx,'frame_idx']\n",
    "        image_path = self.image_root + str(video_idx) + '/img%s.jpg'%frame_idx\n",
    "        label = self.dataset.loc[idx,'label']\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "image_src_path = '/Users/Jipeng/PycharmProjects/simulated_multisensory_integration/data/images/'\n",
    "transform = transforms.ToTensor()\n",
    "image_dataset = ImageDataset(df,image_src_path,transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def train_test_loader(train_ratio,dataset):\n",
    "    n_data = len(dataset)\n",
    "    split = int(n_data*train_ratio)\n",
    "\n",
    "    indices = list(range(n_data))\n",
    "    train_sampler = sampler.SubsetRandomSampler(indices[:split])\n",
    "    test_sampler = sampler.SubsetRandomSampler(indices[split:])\n",
    "\n",
    "    train_loader = DataLoader(dataset, sampler=train_sampler, shuffle=False, batch_size=4)\n",
    "    test_loader = DataLoader(dataset, sampler=test_sampler, shuffle=False, batch_size=4)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "train_loader, test_loader = train_test_loader(0.7,image_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # Conv2d(in_channels, out_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(3,6,10)\n",
    "        self.pool = nn.MaxPool2d(10,10)\n",
    "        self.conv2 = nn.Conv2d(6,16,10)\n",
    "        self.fc1 = nn.Linear(960/4,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,len(loc_map))\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,960/4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr = 0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 2.193\n",
      "[1,    40] loss: 1.910\n",
      "[1,    60] loss: 1.962\n",
      "[1,    80] loss: 1.834\n",
      "[1,   100] loss: 1.746\n",
      "[1,   120] loss: 1.769\n",
      "[1,   140] loss: 1.700\n",
      "[1,   160] loss: 1.616\n",
      "[1,   180] loss: 1.630\n",
      "[1,   200] loss: 1.805\n",
      "[1,   220] loss: 1.640\n",
      "[1,   240] loss: 1.741\n",
      "[1,   260] loss: 1.707\n",
      "[1,   280] loss: 1.477\n",
      "[1,   300] loss: 1.699\n",
      "[1,   320] loss: 1.557\n",
      "[1,   340] loss: 1.656\n",
      "[1,   360] loss: 1.758\n",
      "[1,   380] loss: 1.817\n",
      "[1,   400] loss: 1.836\n",
      "[1,   420] loss: 1.497\n",
      "[1,   440] loss: 1.590\n",
      "[1,   460] loss: 1.612\n",
      "[1,   480] loss: 1.601\n",
      "[1,   500] loss: 1.590\n",
      "[1,   520] loss: 1.545\n",
      "[1,   540] loss: 1.681\n",
      "[1,   560] loss: 1.576\n",
      "[1,   580] loss: 1.677\n",
      "[1,   600] loss: 1.762\n",
      "[1,   620] loss: 1.612\n",
      "[1,   640] loss: 1.650\n",
      "[1,   660] loss: 1.602\n",
      "[1,   680] loss: 1.636\n",
      "[1,   700] loss: 1.451\n",
      "[1,   720] loss: 1.738\n",
      "[1,   740] loss: 1.866\n",
      "[1,   760] loss: 1.740\n",
      "[1,   780] loss: 1.578\n",
      "[1,   800] loss: 1.793\n",
      "[1,   820] loss: 1.773\n",
      "[1,   840] loss: 1.739\n",
      "[1,   860] loss: 1.749\n",
      "[1,   880] loss: 1.593\n",
      "[1,   900] loss: 1.502\n",
      "[1,   920] loss: 1.578\n",
      "[1,   940] loss: 1.736\n",
      "[1,   960] loss: 1.707\n",
      "[1,   980] loss: 1.588\n",
      "[1,  1000] loss: 1.651\n",
      "[1,  1020] loss: 1.609\n",
      "[1,  1040] loss: 1.779\n",
      "[1,  1060] loss: 1.652\n",
      "[1,  1080] loss: 1.815\n",
      "[1,  1100] loss: 1.726\n",
      "[1,  1120] loss: 1.623\n",
      "[1,  1140] loss: 1.535\n",
      "[1,  1160] loss: 1.432\n",
      "[1,  1180] loss: 1.651\n",
      "[1,  1200] loss: 1.589\n",
      "[1,  1220] loss: 1.529\n",
      "[1,  1240] loss: 1.687\n",
      "[1,  1260] loss: 1.766\n",
      "[1,  1280] loss: 1.754\n",
      "[1,  1300] loss: 1.527\n",
      "[1,  1320] loss: 1.846\n",
      "[1,  1340] loss: 1.703\n",
      "[1,  1360] loss: 1.581\n",
      "[1,  1380] loss: 1.600\n",
      "[1,  1400] loss: 1.617\n",
      "[1,  1420] loss: 1.600\n",
      "[1,  1440] loss: 1.729\n",
      "[1,  1460] loss: 1.494\n",
      "[1,  1480] loss: 1.467\n",
      "[1,  1500] loss: 1.668\n",
      "[1,  1520] loss: 1.549\n",
      "[1,  1540] loss: 1.466\n",
      "[1,  1560] loss: 1.807\n",
      "[1,  1580] loss: 1.772\n",
      "[1,  1600] loss: 1.664\n",
      "[1,  1620] loss: 1.567\n",
      "[1,  1640] loss: 1.857\n",
      "[1,  1660] loss: 1.744\n",
      "[1,  1680] loss: 1.620\n",
      "[1,  1700] loss: 1.581\n",
      "[1,  1720] loss: 1.585\n",
      "[1,  1740] loss: 1.666\n",
      "[1,  1760] loss: 1.655\n",
      "[1,  1780] loss: 1.583\n",
      "[1,  1800] loss: 1.567\n",
      "[1,  1820] loss: 1.731\n",
      "[1,  1840] loss: 1.551\n",
      "[1,  1860] loss: 1.614\n",
      "Finished Training\n",
      "[2,    20] loss: 1.582\n",
      "[2,    40] loss: 1.829\n",
      "[2,    60] loss: 1.486\n",
      "[2,    80] loss: 1.765\n",
      "[2,   100] loss: 1.620\n",
      "[2,   120] loss: 1.719\n",
      "[2,   140] loss: 1.503\n",
      "[2,   160] loss: 1.667\n",
      "[2,   180] loss: 1.606\n",
      "[2,   200] loss: 1.692\n",
      "[2,   220] loss: 1.503\n",
      "[2,   240] loss: 1.668\n",
      "[2,   260] loss: 1.745\n",
      "[2,   280] loss: 1.746\n",
      "[2,   300] loss: 1.523\n",
      "[2,   320] loss: 1.489\n",
      "[2,   340] loss: 1.717\n",
      "[2,   360] loss: 1.581\n",
      "[2,   380] loss: 1.450\n",
      "[2,   400] loss: 1.530\n",
      "[2,   420] loss: 1.543\n",
      "[2,   440] loss: 1.607\n",
      "[2,   460] loss: 1.420\n",
      "[2,   480] loss: 1.452\n",
      "[2,   500] loss: 1.466\n",
      "[2,   520] loss: 1.293\n",
      "[2,   540] loss: 1.372\n",
      "[2,   560] loss: 1.248\n",
      "[2,   580] loss: 1.381\n",
      "[2,   600] loss: 1.365\n",
      "[2,   620] loss: 1.293\n",
      "[2,   640] loss: 1.370\n",
      "[2,   660] loss: 1.206\n",
      "[2,   680] loss: 1.305\n",
      "[2,   700] loss: 1.102\n",
      "[2,   720] loss: 1.147\n",
      "[2,   740] loss: 1.164\n",
      "[2,   760] loss: 0.941\n",
      "[2,   780] loss: 1.085\n",
      "[2,   800] loss: 1.071\n",
      "[2,   820] loss: 0.832\n",
      "[2,   840] loss: 0.898\n",
      "[2,   860] loss: 0.761\n",
      "[2,   880] loss: 0.628\n",
      "[2,   900] loss: 0.567\n",
      "[2,   920] loss: 0.674\n",
      "[2,   940] loss: 0.497\n",
      "[2,   960] loss: 0.581\n",
      "[2,   980] loss: 0.502\n",
      "[2,  1000] loss: 0.432\n",
      "[2,  1020] loss: 0.637\n",
      "[2,  1040] loss: 0.460\n",
      "[2,  1060] loss: 0.421\n",
      "[2,  1080] loss: 0.639\n",
      "[2,  1100] loss: 0.548\n",
      "[2,  1120] loss: 0.322\n",
      "[2,  1140] loss: 0.336\n",
      "[2,  1160] loss: 0.377\n",
      "[2,  1180] loss: 0.394\n",
      "[2,  1200] loss: 0.285\n",
      "[2,  1220] loss: 0.529\n",
      "[2,  1240] loss: 0.421\n",
      "[2,  1260] loss: 0.417\n",
      "[2,  1280] loss: 0.380\n",
      "[2,  1300] loss: 0.300\n",
      "[2,  1320] loss: 0.228\n",
      "[2,  1340] loss: 0.185\n",
      "[2,  1360] loss: 0.454\n",
      "[2,  1380] loss: 0.353\n",
      "[2,  1400] loss: 0.369\n",
      "[2,  1420] loss: 0.366\n",
      "[2,  1440] loss: 0.260\n",
      "[2,  1460] loss: 0.281\n",
      "[2,  1480] loss: 0.207\n",
      "[2,  1500] loss: 0.252\n",
      "[2,  1520] loss: 0.151\n",
      "[2,  1540] loss: 0.163\n",
      "[2,  1560] loss: 0.175\n",
      "[2,  1580] loss: 0.143\n",
      "[2,  1600] loss: 0.144\n",
      "[2,  1620] loss: 0.218\n",
      "[2,  1640] loss: 0.240\n",
      "[2,  1660] loss: 0.194\n",
      "[2,  1680] loss: 0.187\n",
      "[2,  1700] loss: 0.219\n",
      "[2,  1720] loss: 0.126\n",
      "[2,  1740] loss: 0.320\n",
      "[2,  1760] loss: 0.248\n",
      "[2,  1780] loss: 0.199\n",
      "[2,  1800] loss: 0.171\n",
      "[2,  1820] loss: 0.138\n",
      "[2,  1840] loss: 0.128\n",
      "[2,  1860] loss: 0.150\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "test = 0\n",
    "for i, data in enumerate(train_loader):\n",
    "    image,label = data\n",
    "    #print (image,label)\n",
    "    if test == 0:\n",
    "        break\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        #print (inputs.shape)\n",
    "        # Clears the gradients of all optimized tensors\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        #print outputs.shape, labels.shape\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:\n",
    "            print ('[%d, %5d] loss: %.3f'%\n",
    "                   (epoch+1, i+1, running_loss/20))\n",
    "            running_loss = 0.0\n",
    "    print ('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_path = './visual_infer.pth'\n",
    "torch.save(net.state_dict(),net_path)\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(net_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing progress:  2%\n",
      "Accuracy of position -4 : 0 %\n",
      "Accuracy of position -3 : 0 %\n",
      "Accuracy of position -2 : 38 % and the total number is 18\n",
      "Accuracy of position -1 : 0 %\n",
      "Accuracy of position 0 : 0 %\n",
      "Accuracy of position 1 : 0 %\n",
      "Accuracy of position  2 : 91 % and the total number is 58\n",
      "Accuracy of position 3 : 0 %\n",
      "Accuracy of position 4 : 0 %\n",
      "The true accuracy of the network is 21 %\n",
      "The approximate accuracy of the network is 78 %\n"
     ]
    }
   ],
   "source": [
    "true_correct = 0\n",
    "approximate_correct = 0\n",
    "total = 0\n",
    "scope = 1\n",
    "loc_map = range(-4,5)\n",
    "position_correct = list(0 for i in range(len(loc_map)))\n",
    "position_total = list(0 for i in range(len(loc_map)))\n",
    "progress = 0.0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "         progress += 1\n",
    "         #print progress,len(test_loader)\n",
    "         if progress == 20:\n",
    "            print ('Testing progress: %2d%%'%(progress/(len(test_loader))*100))\n",
    "            break\n",
    "         test_inputs, test_labels = data\n",
    "         test_outputs = net(test_inputs)\n",
    "         _,predicted = torch.max(test_outputs.data,1)\n",
    "         #print(predicted, test_label)\n",
    "         total += test_labels.size(0)\n",
    "         true_correct += (predicted == test_labels).sum().item()\n",
    "         c = [0 for i in range(4)]\n",
    "         for i in range(test_labels.size(0)):\n",
    "             if test_labels[i]-scope <= predicted[i] <= test_labels[i]+scope:\n",
    "                 position_correct[predicted[i]] += 1\n",
    "             position_total[predicted[i]] += 1\n",
    "for i in range(len(position_total)):\n",
    "    approximate_correct += position_correct[i]\n",
    "    if position_total[i] == 0:\n",
    "        print('Accuracy of position %d : %d %%'%(loc_map[i], 0))\n",
    "    else:\n",
    "        print('Accuracy of position %2s : %d %% and the total number is %d'%(loc_map[i], 100 * position_correct[i]/position_total[i],position_total[i]))\n",
    "print( 'The true accuracy of the network is %d %%'%(100 * true_correct/total))\n",
    "print( 'The approximate accuracy of the network is %d %%'%(100 * approximate_correct/total))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-20495502",
   "language": "python",
   "display_name": "PyCharm (dopamine_rl)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}