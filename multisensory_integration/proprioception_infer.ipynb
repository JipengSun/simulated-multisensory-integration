{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10718\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "src_path = '/Users/Jipeng/PycharmProjects/simulated_multisensory_integration/data/'\n",
    "file_name = 'simulated_data.csv'\n",
    "df = pd.read_csv(src_path+file_name)\n",
    "print (df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of the module\n",
    "Training the proprioceptive inference model. Use the two joints angle data to predict the position of the hand.\n",
    "\n",
    "### Input\n",
    "shoulder_angle, elbow_angle, elbow_x, elbow_y\n",
    "\n",
    "What precision should the input be divided into? It depends on the performance. I will explore later.\n",
    "\n",
    "### Output\n",
    "spatial_coding of hand position\n",
    "\n",
    "Depends on the precision of the final coding, the area can be divided into N parts. So there are N position labels. From [1,0,0,...0] to [0,0,0,...1]\n",
    "\n",
    "### Model structure\n",
    "input-->F-->FC-->FC\n",
    "### To do\n",
    "1. Let the model run, without considering the performance.<br>\n",
    "a. Convert the hand position into spatial coding.<br>\n",
    "b. Split the dataset.<br>\n",
    "c. Use PyTorch to design the model.\n",
    "\n",
    "2. Augment the data, let it cover more positions.\n",
    "3. Divide the data into appropriate precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n# Test the function, delete later.\\nprint (df['hand_x'])\\nprint (np.around(df['hand_x']))\\nprint (df.loc[:,['elbow_angle','shoulder_angle']])\\nprint (df.shape[0])\\n\""
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Test the function, delete later.\n",
    "print (df['hand_x'])\n",
    "print (np.around(df['hand_x']))\n",
    "print (df.loc[:,['elbow_angle','shoulder_angle']])\n",
    "print (df.shape[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'elbow_angle', 'elbow_x', 'elbow_y', 'frame_idx', 'hand_x', 'hand_y', 'shoulder_angle', 'target_x', 'video_idx']\n"
     ]
    }
   ],
   "source": [
    "loc_map = range(-4,5)\n",
    "def label_function(x):\n",
    "    loc_map = range(-4,5)\n",
    "    return loc_map.index(x)\n",
    "    \n",
    "feature_names = df.columns.tolist()\n",
    "print feature_names\n",
    "\n",
    "label = np.around(df['hand_x'])\n",
    "df['label'] = np.around(df['hand_x'])\n",
    "df['label1'] = df['label'].astype(np.int)\n",
    "df['label'] = df['label1'].apply(label_function)\n",
    "#print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "class ArmDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.dataset = df\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        shoulder_angle = self.dataset.loc[idx,'shoulder_angle']\n",
    "        elbow_angle = self.dataset.loc[idx,'elbow_angle']\n",
    "        elbow_x = self.dataset.loc[idx,'elbow_x']\n",
    "        elbow_y = self.dataset.loc[idx,'elbow_y']\n",
    "        #elbow_angle = self.dataset.loc[idx,'elbow_angle']\n",
    "        label = self.dataset.loc[idx,'label']\n",
    "        sample = {'shoulder_angle':shoulder_angle,'elbow_angle':elbow_angle,'elbow_x':elbow_x,'elbow_y':elbow_y,'label':label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(4,15)\n",
    "        self.fc2 = nn.Linear(15,20)\n",
    "        self.fc3 = nn.Linear(20,len(loc_map))\n",
    "    def forward(self,x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr = 0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_loader(train_ratio,dataset):\n",
    "    n_data = len(dataset)\n",
    "    split = int(n_data*train_ratio)\n",
    "    \n",
    "    indices = list(range(n_data))\n",
    "    train_sampler = sampler.SubsetRandomSampler(indices[:split])\n",
    "    test_sampler = sampler.SubsetRandomSampler(indices[split:])\n",
    "    \n",
    "    train_loader = DataLoader(dataset, sampler=train_sampler, shuffle=False, batch_size=4)\n",
    "    test_loader = DataLoader(dataset, sampler=test_sampler, shuffle=False, batch_size=4)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.877\n",
      "[1,   200] loss: 1.579\n",
      "[1,   300] loss: 1.421\n",
      "[1,   400] loss: 1.366\n",
      "[1,   500] loss: 1.337\n",
      "[1,   600] loss: 1.283\n",
      "[1,   700] loss: 1.230\n",
      "[1,   800] loss: 1.271\n",
      "[1,   900] loss: 1.161\n",
      "[1,  1000] loss: 1.471\n",
      "[1,  1100] loss: 1.246\n",
      "[1,  1200] loss: 1.281\n",
      "[1,  1300] loss: 1.197\n",
      "[1,  1400] loss: 1.171\n",
      "[1,  1500] loss: 1.236\n",
      "[1,  1600] loss: 1.207\n",
      "[1,  1700] loss: 1.185\n",
      "[1,  1800] loss: 1.147\n",
      "Finished Training\n",
      "[2,   100] loss: 1.026\n",
      "[2,   200] loss: 1.062\n",
      "[2,   300] loss: 1.211\n",
      "[2,   400] loss: 1.495\n",
      "[2,   500] loss: 1.265\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#df = df[df['label']>=0]\n",
    "#df = df.reset_index(drop=True)\n",
    "arm_dataset = ArmDataset(df)\n",
    "# Dataloader for the whole dataset\n",
    "'''\n",
    "arm_dataloader = DataLoader(arm_dataset,batch_size=4, shuffle=True)\n",
    "for idx, batch_samples in enumerate(arm_dataloader):\n",
    "    shoulder_batches, elbow_batches, label_batches = batch_samples['shoulder_angle'],batch_samples['elbow_angle'],batch_samples['label']\n",
    "    #print(shoulder_batches,label_batches)\n",
    "'''\n",
    "\n",
    "train_loader, test_loader = train_test_loader(0.7,arm_dataset)\n",
    "\n",
    "loss_list = [1000,1000,1000]\n",
    "checkpoint = 1\n",
    "earlystop = True\n",
    "stop = False\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for idx, batch_samples in enumerate(train_loader, 0):\n",
    "        shoulder_batches, elbow_batches, ex_batches, ey_batches, label_batches = batch_samples['shoulder_angle'],batch_samples['elbow_angle'],batch_samples['elbow_x'],batch_samples['elbow_y'],batch_samples['label']\n",
    "        # Clears the gradients of all optimized tensors\n",
    "        optimizer.zero_grad()\n",
    "        shoulder_batches = shoulder_batches.view(1,-1)\n",
    "        elbow_batches = elbow_batches.view(1,-1)\n",
    "        ex_batches = ex_batches.view(1,-1)\n",
    "        ey_batches = ey_batches.view(1,-1)\n",
    "        inputs = torch.cat([shoulder_batches,elbow_batches,ex_batches, ey_batches],dim=0).T\n",
    "        #print (inputs, label_batches)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs,label_batches)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if idx % 100 == 99:\n",
    "            checkpoint+=1\n",
    "            loss_list.append(running_loss/100)\n",
    "            print ('[%d, %5d] loss: %.3f'%\n",
    "                   (epoch+1, idx+1, running_loss/100))\n",
    "            running_loss = 0.0\n",
    "            if loss_list[checkpoint] > loss_list[checkpoint-1] > loss_list[checkpoint-2] > loss_list[checkpoint-3] and earlystop:\n",
    "                stop = True\n",
    "                break\n",
    "        if stop:\n",
    "            break\n",
    "    \n",
    "    print ('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of position -4 : 0 %\n",
      "Accuracy of position -3 : 0 %\n",
      "Accuracy of position -2 : 0 %\n",
      "Accuracy of position -1 : 0 %\n",
      "Accuracy of position  0 : 59 % and the total number is 944\n",
      "Accuracy of position  1 : 55 % and the total number is 2272\n",
      "Accuracy of position 2 : 0 %\n",
      "Accuracy of position 3 : 0 %\n",
      "Accuracy of position 4 : 0 %\n",
      "The true accuracy of the network is 31 %\n",
      "The approximate accuracy of the network is 56 %\n"
     ]
    }
   ],
   "source": [
    "true_correct = 0\n",
    "approximate_correct = 0\n",
    "total = 0\n",
    "scope = 1\n",
    "loc_map = range(-4,5)\n",
    "position_correct = list(0 for i in range(len(loc_map)))\n",
    "position_total = list(0 for i in range(len(loc_map)))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "         test_shoulder, test_elbow, test_ex, test_ey, test_label = data['shoulder_angle'],data['elbow_angle'],data['elbow_x'],data['elbow_y'],data['label']\n",
    "         test_shoulder = test_shoulder.view(1,-1)\n",
    "         test_elbow = test_elbow.view(1,-1)\n",
    "         test_ex = test_ex.view(1,-1)\n",
    "         test_ey = test_ey.view(1,-1)\n",
    "         test_inputs = torch.cat([test_shoulder,test_elbow,test_ex,test_ey],dim=0).T\n",
    "         test_outputs = net(test_inputs)\n",
    "         _,predicted = torch.max(test_outputs.data,1)\n",
    "         #print(predicted, test_label)\n",
    "         total += test_label.size(0)\n",
    "         true_correct += (predicted == test_label).sum().item()\n",
    "         c = [0 for i in range(4)]\n",
    "         for i in range(test_label.size(0)):\n",
    "             if test_label[i]-scope <= predicted[i] <= test_label[i]+scope:\n",
    "                 position_correct[predicted[i]] += 1\n",
    "             position_total[predicted[i]] += 1\n",
    "for i in range(len(position_total)):\n",
    "    approximate_correct += position_correct[i]\n",
    "    if position_total[i] == 0:\n",
    "        print('Accuracy of position %d : %d %%'%(loc_map[i], 0))\n",
    "    else:\n",
    "        print('Accuracy of position %2s : %d %% and the total number is %d'%(loc_map[i], 100 * position_correct[i]/position_total[i],position_total[i]))\n",
    "print( 'The true accuracy of the network is %d %%'%(100 * true_correct/total))\n",
    "print( 'The approximate accuracy of the network is %d %%'%(100 * approximate_correct/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "arm_dataloader = DataLoader(arm_dataset,batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for idx, batch_samples in enumerate(arm_dataloader):\n",
    "        shoulder_batches, elbow_batches, ex_batches, ey_batches, label_batches = batch_samples['shoulder_angle'],batch_samples['elbow_angle'],batch_samples['elbow_x'],batch_samples['elbow_y'],batch_samples['label']        #print(shoulder_batches,label_batches)\n",
    "        optimizer.zero_grad()\n",
    "        shoulder_angle = shoulder_batches.view(1,-1)\n",
    "        elbow_angle = elbow_batches.view(1,-1)\n",
    "        ex = ex_batches.view(1,-1)\n",
    "        ey = ey_batches.view(1,-1)\n",
    "        inputs = torch.cat([shoulder_angle,elbow_angle,ex, ey],dim=0).T\n",
    "        #print (inputs, label_batches)\n",
    "        outputs = net(inputs)\n",
    "        l1 = outputs.tolist()\n",
    "        df.loc[idx,'priopredict'] = ' '.join(str(i) for i in l1[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        -0.60513406992 0.565839469433 1.33064591885 0....\n",
      "1        -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "2        -0.60513406992 0.565839469433 1.33064591885 0....\n",
      "3        -0.605134129524 0.565839350224 1.33064568043 0...\n",
      "4        -0.60513406992 0.565839469433 1.33064591885 0....\n",
      "5        -0.605134487152 0.565838515759 1.33064472675 0...\n",
      "6        -0.60513406992 0.565839469433 1.33064591885 0....\n",
      "7        -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "8        -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "9        -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "11       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "12       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "13       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "14       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "15       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "16       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "17       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "18       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "19       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "20       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "21       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "22       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "23       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "24       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "25       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "26       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "27       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "28       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "29       -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "                               ...                        \n",
      "10688    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10689    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10690    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10691    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10692    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10693    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10694    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10695    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10696    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10697    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10698    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10699    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10700    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10701    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10702    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10703    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10704    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10705    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10706    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10707    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10708    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10709    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10710    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10711    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10712    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10713    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10714    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10715    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10716    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "10717    -0.605134010315 0.565839529037 1.33064591885 0...\n",
      "Name: priopredict, Length: 10718, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print df['priopredict']\n",
    "df.to_csv('/Users/Jipeng/PycharmProjects/simulated_multisensory_integration/data/after_prio.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (dopamine_rl)",
   "language": "python",
   "name": "pycharm-20495502"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}